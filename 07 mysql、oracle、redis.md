### 数据库分类

关系型数据库：最典型的数据结构是表，是二维表和其之间的联系所组成的数据组织

- 优点：易于维护，都是使用表结构，格式一致；使用方便，SQL语言通用，可用于复杂查询。
- 缺点：读写性能比较差，尤其是海量数据的高效率读写；固定的表结构，灵活性稍微欠缺。

非关系型数据库：一种数据结构化存储方法的集合，可以是文档或者键值对

- 优点：格式灵活，存储数据的格式可以是键值对形式、文档形式、图片形式等；速度快，nosql可以使用硬盘或者随机存储器作为载体，关系型数据库只能使用硬盘；高扩展性；成本低，nosql部署简单，基本上都是开源软件。

- 缺点：无事务处理；复杂查询方面欠缺。

### 数据库范式

**1NF(第一范式)**

要求数据库表的<u>每一列都是不可分割的原子数据项</u>。（比如“家庭信息”、“学校信息”就不满足原子性的要求，应该分成“家庭人口”、“户籍”、“学历”、“所在年级”）

**2NF(第二范式)**

第二范式需要确保数据库表中的<u>每一列都和主键相关</u>，而不能只与主键的某一部分相关（主要针对联合主键而言）。（比如订单表中主键是“订单号”+“产品号”，这时“订单金额”、“订单时间”和主键的某一部分“产品号”没有关系，应该将这两个字段分出去另建一张表）

**3NF(第三范式)**

第三范式需要确保数据表中的<u>每一列数据都和主键直接相关</u>，而不能间接相关。（比如班级表的主键是“学生学号”，但“班主任姓名”、“班主任年龄”直接依赖的是“教工号”，而不是“学生学号”，因此班级表中应该只有“教工号”，不应该再有班主任的其他信息）

### 数据库设计步骤

1. **需求分析** : 分析用户的需求，包括数据、功能和性能需求。
2. **概念结构设计** : 主要采用E-R模型进行设计，包括画E-R图。
3. **逻辑结构设计** : 通过将E-R图转换成表，实现从E-R模型到关系模型的转换。
4. **物理结构设计** : 主要是为所设计的数据库选择合适的存储结构和存取路径。
5. **数据库实施** : 包括编程、测试和试运行
6. **数据库的运行和维护** : 系统的运行与数据库的日常维护。

> E-R图也称实体-联系图(Entity Relationship Diagram)，提供了表示实体类型、属性和联系的方法，是表示概念关系模型的一种方式。

### 主键 vs 外键

- **主键(主码)** ：主键用于唯一标识一条数据，不能有重复，不允许为空。一张表只能有一个主键。
- **外键(外码)** ：外键用来和其他表建立联系用，外键是另一张表的主键，外键是可以有重复的，可以是空值。一个表可以有多个外键。

### 什么是存储过程

我们可以把存储过程看成是一些 SQL 语句的集合，中间加了点逻辑控制语句。存储过程在业务比较复杂的时候是非常实用的，比如很多时候我们完成一个操作可能需要写一大串SQL语句，这时候我们就可以写有一个存储过程，这样也方便了我们下一次的调用。存储过程一旦调试完成通过后就能稳定运行，另外，使用存储过程比单纯SQL语句执行要快，因为存储过程是预编译过的。

### DML vs DDL

- DML （Data Manipulation Language）是数据操作语言的缩写，是指对数据库中表记录的操作，主要包括表记录的插入（insert）、更新（update）、删除（delete）和查询（select）。
- DDL （Data Definition Language）是数据定义语言的缩写，是对数据库内部的对象进行创建、删除、修改的操作语言。

DML 只是对表内部数据的操作，而不涉及到表的定义、结构的修改，更不会涉及到其他对象。

### drop、delete与truncate

- drop(丢弃数据): drop table 表名 ，直接将表都删除掉，在删除表的时候使用。
- truncate (清空数据) : truncate table 表名 ，只删除表中的数据，再插入数据的时候自增长id又从1开始，在清空表中数据的时候使用。
- delete(删除数据) : delete from 表名 where 列名=值，删除某一列的数据，如果不加 where 子句和truncate 作用类似。

一般来说作用范围：drop>truncate>delete

drop 和truncate属于DDL，操作立即生效，不能回滚，操作不触发 trigger。而 delete 语句是DML，事务提交之后才生效。

### 表级锁 vs 行级锁

- 表级锁：对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。
- 行级锁：只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

### MyISAM vs InnoDB

MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的 ISAM （Indexed Sequential Access Method：有索引的顺序访问方法）所改良，虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（另一种数据库引擎）。

大多数时候我们使用的都是InnoDB存储引擎，但是在某些情况下使用 MyISAM 也是合适的比如读密集的情况下。

**两者的对比：**

1. 是否支持行级锁 : MyISAM 只有表级锁，而InnoDB 支持行级锁和表级锁，默认为行级锁。
2. 是否支持事务和崩溃后的安全恢复： MyISAM 强调的是性能，每次查询具有原子性，其执行速度比InnoDB更快，但是不提供事务支持。InnoDB 提供事务支持，外部键等高级数据库功能。 
3. 是否支持外键： MyISAM不支持，InnoDB支持。
4. 是否支持MVCC ：仅 InnoDB 支持。应对高并发事务MVCC比单纯的加锁更高效；MVCC只在读取已提交和可重复读两个隔离级别下工作；MVCC可以使用乐观锁和悲观锁来实现。

> Multi-Version Concurrency Control 多版本[并发控制](https://baike.baidu.com/item/并发控制/3543545)，MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问；在编程语言中实现事务内存。

### 表的优化措施

1. 限定数据的范围：禁止不带任何限制数据范围条件的查询语句；

2. 读写分离：经典的数据库拆分方案，主库负责写，从库负责读；

3. 垂直分区：根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 
   - 优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。
   - 缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂。

4. 水平分区：水平拆分是指行的拆分，保持表结构不变，通过某种策略存储数据分片；这样每一片数据分散到不同的表或者库中，达到了分布式的目的； 水平拆分可以支撑非常大的数据量。

   分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以水平拆分最好分库 。

   《Java工程师修炼之道》的作者推荐**尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度** ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

数据库分片的两种常见方案：

- 客户端代理：分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。 当当网的 Sharding-JDBC 、阿里的TDDL是两种比较常用的实现。
- 中间件代理：在应用和数据中间加了一个代理层，分片逻辑统一维护在中间件服务中。 Mycat 、360的Atlas、网易的DDB等等都是这种架构的实现。

### MySQL vs Oracle

**数据类型**：

- MySQL的非空字段也有空的内容，Oracle里定义了非空字段就不容许有空的内容；
- MySQL直接在sql语句中写limit就可以实现分页，Oracle需要用到伪列rownum和嵌套查询；
- MySql使用双引号来包起字符串，Oracle使用单引号包起字符串；
- MySQL日期字段分DATE（年月日）和TIME（时分秒）两种，Oracle日期字段只有DATE，包含年月日时分秒信息；
- MySql一般使用自动增长类型，在创建表的时候只要指定表的主键为auto increment，插入记录时就不需要再为主键添加记录了，主键会自动增长；Oracle中没有自动增长，主键一般使用序列，插入记录时将序列号的下一个值付给该字段即可；

**权限管理**：

- Oracle：一个库有多个用户，每个用户有自己的表
- MySql：多个用户共享每个库，每个库有自己的表

**隔离级别**：

- mysql默认的事务处理级别是REPEATABLE-READ（可重复读）；
- oracle支持READ COMMITTED（读已提交） 和 SERIALIZABLE（可串行化）这两种事务隔离级别，默认是读已提交；

## 事务

### 事务的特性

事务是逻辑上的一组操作，要么都执行，要么都不执行

事务的特性（ACID）

- 原子性（Atomicity）：事务中所涉及的程序对数据库的修改操作要么全部成功，要么全部失败。
- 一致性（Consistency）：执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的。
- 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据是独立的，相互不影响。
- 持久性（Durubility）：一旦事务成功提交，它对数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### 事务的并发

- 脏读：读取未提交数据；A事务读取B事务尚未提交的数据，此时如果B事务发生错误并执行回滚操作，那么A事务读取到的数据就是脏数据。
- 不可重复读：在一个事务中前后两次读取的结果不一致。
- 幻读：在一个事务中前后两次统计数据总量不一致。

不可重复读的重点是修改，幻读的重点在于新增或者删除。


### 事务隔离级别

1. read uncommitted 读取未提交：允许读取尚未提交的数据变更。
2. read committed 读取已提交：事务成功提交后才可以被查询到。

3. repeatable 可重复读：对同一字段的多次读取结果是一致的，但可能将未提交的记录查询出来，而出现幻读。

4. Serializable 可串行化：所有的事务依次逐个执行，在每个读数据行上添加共享锁，这样事务之间就完全不可能产生干扰，会导致大量超时现象和锁竞争。

| **隔离级别** | **脏读** | **不可重复读** | **幻读** |
| ------------ | -------- | -------------- | -------- |
| 读取未提交   | √        | √              | √        |
| 读取已提交   | ×        | √              | √        |
| 可重复读     | ×        | ×              | √        |
| 可串行化     | ×        | ×              | ×        |

## 索引

索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。

### 为什么索引能提高查询速度

MySQL的基本存储结构是页(记录都存在页里边)：

- **各个数据页可以组成一个双向链表**
- **每个数据页中的记录又可以组成一个单向链表**

  - 每个数据页都会为存储在它里边的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应的分组即可快速找到指定的记录

  - 以其他列(非主键)作为搜索条件时只能从最小记录开始依次遍历单链表中的每条记录。


当使用没有索引的非主键进行查询时，默认会这样做（时间复杂度为O（n））：

1. 定位到记录所在的页：需要遍历双向链表，找到所在的页
2. 从所在的页内中查找相应的记录：遍历所在页的单链表

索引将无序的数据变成有序(相对)，通过 “目录” 可以很快地定位到对应的页上（二分查找，时间复杂度近似为O(logn)）。

### 最左前缀原则

MySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引。如User表的name和city加联合索引就是(name,city)，而最左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到。如下：

```sql
select * from user where name=xx and city=xx ; ／／可以命中索引
select * from user where name=xx ; // 可以命中索引
select * from user where city=xx ; // 无法命中索引            
```

这里需要注意的是，查询的时候如果两个条件都用上了，但是顺序不同，如 city= xx and name ＝xx，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。

由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDER BY子句也遵循此规则。

### 避免冗余索引

冗余索引指的是索引的功能相同，能够命中后者的查询肯定是能够命中前者的；如（name,city ）和（name ）这两个索引就是冗余索引， 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。

### 索引的类别

```sql
--添加PRIMARY KEY（主键索引）
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 
--添加UNIQUE(唯一索引)
ALTER TABLE `table_name` ADD UNIQUE ( `column` ) 
--添加INDEX(普通索引)
ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
--添加FULLTEXT(全文索引)
ALTER TABLE `table_name` ADD FULLTEXT ( `column`) 
--添加多列索引
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```

## 乐观锁与悲观锁

### 悲观锁

总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在**拿数据的时候都会上锁**，这样别人想拿这个数据就会阻塞直到拿到锁，一般多写的场景下用悲观锁就比较合适。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁、表锁、读锁、写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

### 乐观锁

总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是**在更新的时候会判断一下在此期间别人有没有去更新这个数据**，可以使用<u>版本号机制和CAS算法</u>实现。乐观锁适用于多读少写的应用场景，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。

### 乐观锁的实现方式

乐观锁一般会使用版本号机制或CAS算法实现

**版本号机制**

一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值与当前数据库中的version值相等时才更新。

**CAS算法**

即compare and swap（比较与交换），是一种有名的无锁算法。即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数

- 需要读写的内存值 V
- 进行比较的值 A
- 拟写入的新值 B

当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，一般情况下是一个自旋操作，即不断的重试。

### **CAS**算法的缺点

1. ABA 问题

   如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？

2. 循环时间长开销大

   自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 

3. 只能保证一个共享变量的原子操作

   CAS 只对单个共享变量有效，当操作涉及多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作。

# Redis

### 为什么使用缓存

**高性能：**假如用户第一次访问数据库中的某些数据，这个过程会比较慢，因为是从硬盘上读取的。如果将该用户访问的数据放在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。

**高并发：**直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

### 为什么使用redis 而不用 map 做缓存

缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。

使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached 服务的高可用，整个程序架构上较为复杂。

### redis vs memcached 

1. redis支持更丰富的数据类型（支持更复杂的应用场景）：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储；memcache支持简单的数据类型 String。
2. Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而Memecache把数据全部存在内存之中**。**
3. 集群模式：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的。

### redis 设置过期时间

如果你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？

- **定期删除**：redis默认是每隔 100ms 就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！
- **惰性删除** ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉，这就是所谓的惰性删除。

### redis 内存淘汰机制

MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据？

**redis 提供 6种数据淘汰策略：**

1. **volatile-lru**：从已设置过期时间的数据集中挑选<u>最近最少使用</u>的数据淘汰
2. **volatile-lfu**：从已设置过期时间的数据集中挑选<u>最不经常使用</u>的数据淘汰
3. **volatile-ttl**：从已设置过期时间的数据集中挑选<u>将要过期</u>的数据淘汰
4. **volatile-random**：从已设置过期时间的数据集中<u>随机挑选</u>数据淘汰
5. **allkeys-lru**：当内存不足以容纳新写入数据时，在键空间中，移除<u>最近最少使用</u>的key（最常用）
6. **allkeys-lfu**：当内存不足以容纳新写入数据时，在键空间中，移除<u>最不经常使用</u>的key
7. **allkeys-random**：从数据集中任意选择数据淘汰
8. **no-eviction**：禁止驱逐数据，当内存不足以容纳新写入数据时，新写入操作会报错

### redis 持久化机制

**快照（snapshotting）持久化（RDB）**

Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本，还可以将快照留在原地以便重启服务器的时候使用。

快照持久化是Redis默认采用的持久化方式，在redis.conf配置文件中默认有此下配置：

```
save 900 1 #在900秒(15分钟)之后，至少有1个key发生变化，就会触发BGSAVE命令创建快照。
save 300 10 #在300秒(5分钟)之后，至少有10个key发生变化，就会触发BGSAVE命令创建快照。
save 60 10000 #在60秒(1分钟)之后，至少有10000个key发生变化，就会触发BGSAVE命令创建快照。
```

**AOF（append-only file）持久化**

与快照持久化相比，AOF持久化的实时性更好，因此已成为主流的持久化方案（默认关闭）。

开启AOF持久化后每执行一条会更改Redis中数据的命令，Redis就会将该命令写入硬盘中的AOF文件。

在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

- appendfsync always       #每次有数据修改发生时都会写入AOF文件，这样会严重降低Redis的速度
- appendfsync everysec   #每秒钟同步一次，显示地将多个写命令同步到硬盘
- appendfsync no                #让操作系统决定何时进行同步

为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

**AOF 重写**

AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。

AOF重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任何读入、分析或者写入操作。

在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。

**Redis 4.0 对于持久化机制的优化**

Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点，快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

### redis 事务

Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务(transaction)功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。

### 缓存雪崩

即缓存同一时间大面积的失效，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决办法：

- 事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上；选择合适的内存淘汰策略。
- 事中：本地ehcache缓存 + hystrix限流&降级，避免MySQL崩掉
- 事后：利用 redis 持久化机制保存的数据尽快恢复缓存

### 缓存穿透

一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决办法：最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

### 并发竞争 Key 的问题

所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同。

推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能。

基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。

在实践中，当然是从以可靠性为主。所以首推Zookeeper。

### 缓存与数据库的数据一致性

一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况。串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。







